{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cef685be",
   "metadata": {},
   "source": [
    "# Técnicas Básicas de NLP en Jupyter Notebook\n",
    "\n",
    "\n",
    "Este notebook introduce algunas técnicas fundamentales del Procesamiento del Lenguaje Natural (NLP), una rama de la Inteligencia Artificial que permite a las computadoras comprender y manipular texto en lenguaje humano.\n",
    "\n",
    "Exploraremos diversas técnicas esenciales de NLP con ejemplos en español.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa676fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2900649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sil46\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sil46\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sil46\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Descargar recursos necesarios de NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Cargar modelo de SpaCy\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62199e9",
   "metadata": {},
   "source": [
    "# 1. Tokenización y Normalización\n",
    "\n",
    "La tokenización es el proceso de dividir un texto en unidades más pequeñas (tokens), como palabras o frases.\n",
    "Esto es útil para el análisis de texto, ya que permite tratar cada palabra como una entidad independiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67688417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenización en palabras: ['El', 'procesamiento', 'del', 'lenguaje', 'natural', 'permite', 'a', 'las', 'máquinas', 'entender', 'el', 'lenguaje', 'humano', '.', 'Es', 'una', 'de', 'las', 'áreas', 'más', 'fascinantes', 'de', 'la', 'inteligencia', 'artificial', '.']\n",
      "Tokenización en oraciones: ['El procesamiento del lenguaje natural permite a las máquinas entender el lenguaje humano.', 'Es una de las áreas más fascinantes de la inteligencia artificial.']\n"
     ]
    }
   ],
   "source": [
    "texto = \"genera un parrofo que hable son riogran tieena del fueg\n",
    "ío Grande es una de las ciudades más importantes de la provincia de Tierra del Fuego, Antártida e Islas del Atlántico Sur, en Argentina. Ubicada en la costa noreste de la isla grande, se destaca por su actividad industrial, especialmente en el sector electrónico y textil, así como por su historia vinculada a la ganadería ovina. Además, es conocida como la \"Capital Nacional de la Trucha\" debido a la abundancia de estos peces en sus ríos, lo que atrae a pescadores de todo el mundo. Su clima frío y ventoso, junto con sus paisajes naturales, la convierten en un lugar único en el extremo sur del país.\"\n",
    "palabras_tokenizadas = word_tokenize(texto, language=\"spanish\")\n",
    "oraciones_tokenizadas = sent_tokenize(texto, language=\"spanish\")\n",
    "print(\"Tokenización en palabras:\", palabras_tokenizadas)\n",
    "print(\"Tokenización en oraciones:\", oraciones_tokenizadas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ee1514",
   "metadata": {},
   "source": [
    "# 2. Expresiones Regulares\n",
    "\n",
    "Las expresiones regulares permiten encontrar patrones en textos.\n",
    "Aquí buscamos la palabra 'procesamiento' dentro del texto.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94499f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coincidencias de 'procesamiento': ['procesamiento']\n"
     ]
    }
   ],
   "source": [
    "patron = r\"\\b[Pp]rocesamiento\\b\"\n",
    "coincidencias = re.findall(patron, texto)\n",
    "print(\"Coincidencias de 'procesamiento':\", coincidencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4516874",
   "metadata": {},
   "source": [
    "# 3. Uso de NLTK - Stop Words\n",
    "\"\"\"\n",
    "Las 'stop words' son palabras comunes que suelen eliminarse en el análisis de texto,\n",
    "ya que no aportan demasiado significado (ejemplo: 'el', 'es', 'de').\n",
    "\"\"\"\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "palabras_filtradas = [palabra for palabra in palabras_tokenizadas if palabra.lower() not in stop_words]\n",
    "print(\"Texto sin stop words:\", palabras_filtradas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f35ba1",
   "metadata": {},
   "source": [
    "# 4. Distancias entre strings\n",
    "\"\"\"\n",
    "Las distancias entre cadenas permiten comparar similitud entre palabras,\n",
    "lo que es útil para la corrección ortográfica y el análisis de variantes.\n",
    "\"\"\"\n",
    "def similaridad_cadena(cadena1, cadena2):\n",
    "    return SequenceMatcher(None, cadena1, cadena2).ratio()\n",
    "print(\"Similitud entre 'lenguaje' y 'lengua':\", similaridad_cadena(\"lenguaje\", \"lengua\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c72fad",
   "metadata": {},
   "source": [
    "# 5. Vectorización\n",
    "\"\"\"\n",
    "La vectorización convierte el texto en una representación numérica.\n",
    "Aquí usamos la técnica de Bolsa de Palabras (BoW), que cuenta la frecuencia de cada palabra.\n",
    "\"\"\"\n",
    "corpus = [\n",
    "    \"El procesamiento del lenguaje natural es una rama de la IA.\",\n",
    "    \"Las redes neuronales profundas han mejorado las aplicaciones de NLP.\",\n",
    "    \"Los modelos de lenguaje actuales utilizan grandes volúmenes de datos.\"\n",
    "]\n",
    "vectorizador = CountVectorizer()\n",
    "X = vectorizador.fit_transform(corpus)\n",
    "print(\"Representación BoW:\", X.toarray())\n",
    "print(\"Palabras en el vocabulario:\", vectorizador.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7536596c",
   "metadata": {},
   "source": [
    "# 6. N-gramas\n",
    "\"\"\"\n",
    "Los N-gramas permiten analizar secuencias de palabras en lugar de palabras individuales.\n",
    "Aquí extraemos bigramas (pares de palabras).\n",
    "\"\"\"\n",
    "vectorizador_ngrams = CountVectorizer(ngram_range=(2,2))\n",
    "X_ngrams = vectorizador_ngrams.fit_transform(corpus)\n",
    "print(\"Bigramas:\", vectorizador_ngrams.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfe5bb",
   "metadata": {},
   "source": [
    "# 7. Stemming\n",
    "\"\"\"\n",
    "El stemming reduce las palabras a su raíz, eliminando sufijos.\n",
    "Puede ayudar a agrupar palabras con significados similares.\n",
    "\"\"\"\n",
    "stemmer = PorterStemmer()\n",
    "palabras_stemmed = [stemmer.stem(palabra) for palabra in palabras_filtradas]\n",
    "print(\"Stemming:\", palabras_stemmed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece81a8e",
   "metadata": {},
   "source": [
    "# 8. Lematización\n",
    "\"\"\"\n",
    "La lematización transforma las palabras a su forma base respetando su gramática,\n",
    "lo que mejora el análisis en comparación con el stemming.\n",
    "\"\"\"\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "palabras_lemmatized = [lemmatizer.lemmatize(palabra) for palabra in palabras_filtradas]\n",
    "print(\"Lematización:\", palabras_lemmatized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7584d87",
   "metadata": {},
   "source": [
    "# 9. Uso de SpaCy - Análisis Morfológico\n",
    "\"\"\"\n",
    "SpaCy permite realizar análisis morfológico, extrayendo información gramatical de las palabras.\n",
    "Aquí mostramos la lematización con SpaCy.\n",
    "\"\"\"\n",
    "doc = nlp(texto)\n",
    "print(\"Lematización con SpaCy:\", [token.lemma_ for token in doc])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0542d",
   "metadata": {},
   "source": [
    "# 10. Limitaciones de Bolsa de Palabras\n",
    "\"\"\"\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency) mejora la representación del texto\n",
    "dando más importancia a palabras clave en un conjunto de documentos.\n",
    "\"\"\"\n",
    "vectorizador_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizador_tfidf.fit_transform(corpus)\n",
    "print(\"TF-IDF:\", X_tfidf.toarray())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2f137",
   "metadata": {},
   "source": [
    "# 11. Análisis de Sentimiento con SpaCy\n",
    "\"\"\"\n",
    "Los modelos de análisis de sentimiento pueden evaluar si un texto tiene una connotación positiva, negativa o neutra.\n",
    "Aquí analizamos una reseña sobre NLP.\n",
    "\"\"\"\n",
    "doc = nlp(\"Me fascina el procesamiento del lenguaje natural, pero a veces puede ser desafiante.\")\n",
    "print(\"Tokens y sus sentimientos:\", [(token.text, token.sentiment) for token in doc])\n",
    "\n",
    "### Actividad para los estudiantes:\n",
    "\"\"\"\n",
    "1. Prueba la tokenización con un texto de tu elección.\n",
    "2. Modifica el patrón de expresiones regulares para encontrar la palabra 'inteligencia'.\n",
    "3. Agrega más frases a la vectorización y analiza los resultados.\n",
    "4. Prueba con otras frases en el análisis de sentimiento.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489a1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d825e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
